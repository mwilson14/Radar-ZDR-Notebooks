{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwilson41\\AppData\\Local\\Continuum\\Anaconda3\\envs\\radar\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n"
     ]
    }
   ],
   "source": [
    "### This script will plot some graphics showing the relative locations of the ZDR and KDP maxes in the storm.\n",
    "import matplotlib.pyplot as plt\n",
    "import pyart\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "from metpy.units import atleast_1d, check_units, concatenate, units\n",
    "from matplotlib.patches import PathPatch\n",
    "from matplotlib.path import Path\n",
    "from siphon.radarserver import RadarServer\n",
    "rs = RadarServer('http://thredds-aws.unidata.ucar.edu/thredds/radarServer/nexrad/level2/S3/')\n",
    "#Use the IDD server link if the AWS one doesn't work, or if you're on a non-.edu domain.\n",
    "#rs = RadarServer('http://thredds.ucar.edu/thredds/radarServer/nexrad/level2/IDD/')\n",
    "from datetime import datetime, timedelta\n",
    "from siphon.cdmr import Dataset\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.io.shapereader import Reader\n",
    "from cartopy.feature import ShapelyFeature\n",
    "from metpy.units import atleast_1d, check_units, concatenate, units\n",
    "from shapely.geometry import polygon as sp\n",
    "import pyproj \n",
    "import shapely.ops as ops\n",
    "from shapely.ops import transform\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from functools import partial\n",
    "from shapely import geometry\n",
    "import netCDF4\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage import data, img_as_float\n",
    "from pyproj import Geod\n",
    "from metpy.calc import get_wind_dir\n",
    "import matplotlib.lines as mlines\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in loop\n",
      "21\n",
      "0.44664\n",
      "2017-07-11 23:00:03.084000\n",
      "its this line\n",
      "heres the problem\n",
      "almost gridding\n",
      "made it to smoothing\n",
      "made it through gradient\n",
      "got gradient\n",
      "Set up our projection\n",
      "(-98.825555555555553, 46.027777777777779, <cartopy.crs.PlateCarree object at 0x000002050AFA79E8>)\n",
      "plotting\n",
      "1\n",
      "-97.1934992584136\n",
      "past mask\n",
      "47.3734\n",
      "found a storm\n",
      "added polygon\n",
      "1\n",
      "-97.69793959135923\n",
      "past mask\n",
      "48.1268\n",
      "found a storm\n",
      "added polygon\n",
      "1\n",
      "-97.42070663509443\n",
      "past mask\n",
      "48.2905\n",
      "found a storm\n",
      "found a big storm\n",
      "plotted a big storm\n",
      "made it to beginning of loop\n",
      "2\n",
      "-97.45426796840373\n",
      "added polygon\n",
      "2\n",
      "-97.60889622016505\n",
      "nope\n",
      "2\n",
      "-97.61506305349813\n",
      "nope\n",
      "2\n",
      "-97.35324553835726\n",
      "added polygon\n",
      "made it here\n",
      "made it through zdr centroids\n",
      "1\n",
      "-97.25847127071187\n",
      "[  4.77580462  81.18627664  47.02455746  30.94296107]\n",
      "1\n",
      "-97.11359553646513\n",
      "1\n",
      "-97.74011319832384\n",
      "[ 83.78479127   3.29831057  35.6457257   51.89535964]\n",
      "1\n",
      "-97.58810426781373\n",
      "1\n",
      "-97.46283865335688\n",
      "[ 48.64909764  34.69814364   0.72146509  16.40688364]\n",
      "1\n",
      "-97.62221562993776\n",
      "[ 54.39002306  30.664709    12.45283747  24.39107237]\n",
      "1\n",
      "-97.38880944728031\n",
      "1\n",
      "-97.37549284270315\n",
      "1\n",
      "-97.3770919927621\n",
      "[ 32.75502759  50.51615586  15.9721852    1.78944555]\n",
      "made it through kdp centroids\n",
      "0\n",
      "1\n",
      "-97.4542679684\n",
      "[ 2.52646041  2.89075589  6.07439162  3.89753273]\n",
      "[ 103.92417764   38.97911912]\n",
      "2\n",
      "3\n",
      "4\n",
      "calculating separation\n",
      "Boolean problem here\n",
      "maybe its here\n",
      "or not\n",
      "(0, -97.193499258413595)\n",
      "[]\n",
      "(1, -97.69793959135923)\n",
      "[0]\n",
      "(2, -97.454267968403727)\n",
      "[1]\n",
      "(3, -97.353245538357257)\n",
      "[]\n",
      "made it through giant if statement\n",
      "plotted centroids\n",
      "making dataframe\n",
      "setting index\n",
      "first dataframe\n",
      "made it to plotting\n",
      "consolidated ZDR:\n",
      "consolidated ZDR:\n",
      "means there's a kdp problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwilson41\\AppData\\Local\\Continuum\\Anaconda3\\envs\\radar\\lib\\site-packages\\ipykernel_launcher.py:641: DeprecationWarning: assignment will raise an error in the future, most likely because your index result shape does not match the value array shape. You can use `arr.flat[index] = values` to keep the old behaviour.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure saved\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "0.445614\n",
      "2017-07-11 23:01:54.062000\n",
      "its this line\n",
      "heres the problem\n",
      "almost gridding\n",
      "made it to smoothing\n",
      "made it through gradient\n",
      "got gradient\n",
      "Set up our projection\n",
      "(-98.825555555555553, 46.027777777777779, <cartopy.crs.PlateCarree object at 0x00000205005C1728>)\n",
      "plotting\n",
      "1\n",
      "-98.32695967470418\n",
      "past mask\n",
      "nan\n",
      "1\n",
      "-97.2223701674984\n",
      "past mask\n",
      "47.1039\n",
      "found a storm\n",
      "[  2.12243266  82.25971847  47.87642521  31.61536127]\n",
      "Poly lon -97.2223701674984\n",
      "[-97.19349926 -97.69793959 -97.45426797 -97.35324554]\n",
      "[0 1 2 3]\n",
      "storm id 0\n",
      "added polygon\n",
      "1\n",
      "-97.10865280683211\n",
      "past mask\n",
      "45.6042\n",
      "found a storm\n",
      "[  6.28775837  86.91559199  52.20328127  35.81146171]\n",
      "Poly lon -97.10865280683211\n",
      "[-97.19349926 -97.69793959 -97.45426797 -97.35324554]\n",
      "[0 1 2 3]\n",
      "storm id 0\n",
      "added polygon\n",
      "1\n",
      "-97.67879498032912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwilson41\\AppData\\Local\\Continuum\\Anaconda3\\envs\\radar\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2889: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\mwilson41\\AppData\\Local\\Continuum\\Anaconda3\\envs\\radar\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past mask\n",
      "48.2957\n",
      "found a storm\n",
      "[ 83.04983772   1.51059916  34.44686996  50.84738237]\n",
      "Poly lon -97.67879498032912\n",
      "[-97.19349926 -97.69793959 -97.45426797 -97.35324554]\n",
      "[0 1 2 3]\n",
      "storm id 1\n",
      "added polygon\n",
      "1\n",
      "-97.40472233464726\n",
      "past mask\n",
      "48.0233\n",
      "found a storm\n",
      "found a big storm\n",
      "plotted a big storm\n",
      "made it to beginning of loop\n",
      "2\n",
      "-97.45310833423348\n",
      "[ 48.62868708  34.81830982   0.09962385  16.32321858]\n",
      "Poly lon -97.45310833423348\n",
      "[-97.19349926 -97.69793959 -97.45426797 -97.35324554]\n",
      "[0 1 2 3]\n",
      "storm id 2\n",
      "added polygon\n",
      "2\n",
      "-97.36212798321206\n",
      "nope\n",
      "2\n",
      "-97.5789539153865\n",
      "[ 53.28610404  30.63185974   9.24346237  22.39345425]\n",
      "Poly lon -97.5789539153865\n",
      "[-97.19349926 -97.69793959 -97.45426797 -97.35324554]\n",
      "[0 1 2 3]\n",
      "storm id 2\n",
      "added polygon\n",
      "2\n",
      "-97.34862643068297\n",
      "[ 31.46657699  51.98861946  17.29666943   0.89232765]\n",
      "Poly lon -97.34862643068297\n",
      "[-97.19349926 -97.69793959 -97.45426797 -97.35324554]\n",
      "[0 1 2 3]\n",
      "storm id 3\n",
      "added polygon\n",
      "made it here\n",
      "made it through zdr centroids\n",
      "1\n",
      "-97.24290528034058\n",
      "[  1.71314951   9.86694731  82.24976502  48.04602104  52.11389564\n",
      "  31.0859864 ]\n",
      "1\n",
      "-97.73556356471799\n",
      "[ 83.58352487  88.43564034   4.24620375  36.4435023   31.65113914\n",
      "  53.52461629]\n",
      "1\n",
      "-97.57489668562758\n",
      "1\n",
      "-97.59624462199247\n",
      "[ 51.92736089  57.48013424  31.46434727  10.62542036   1.64578764\n",
      "  23.49372654]\n",
      "1\n",
      "-97.44879500615698\n",
      "[ 47.18185414  51.49136345  35.15881262   0.62633015   9.68519616\n",
      "  16.5882528 ]\n",
      "1\n",
      "-97.52840002796667\n",
      "1\n",
      "-97.35452354408865\n",
      "[ 30.66442947  34.97210959  51.71196724  17.2084676   23.02381232\n",
      "   0.48228775]\n",
      "1\n",
      "-97.22163239322418\n",
      "made it through kdp centroids\n",
      "0\n",
      "1\n",
      "2\n",
      "-97.4531083342\n",
      "[ 4.56922246  6.29938657  5.74021484]\n",
      "[ 91.59098513]\n",
      "3\n",
      "4\n",
      "calculating separation\n",
      "Boolean problem here\n",
      "maybe its here\n",
      "or not\n",
      "(0, -97.222370167498397)\n",
      "[]\n",
      "(1, -97.108652806832112)\n",
      "[]\n",
      "(2, -97.678794980329116)\n",
      "[0]\n",
      "(3, -97.453108334233477)\n",
      "[1]\n",
      "(4, -97.578953915386506)\n",
      "[]\n",
      "(5, -97.34862643068297)\n",
      "[]\n",
      "made it through giant if statement\n",
      "plotted centroids\n",
      "making dataframe\n",
      "setting index\n",
      "made it to plotting\n",
      "consolidated ZDR:\n",
      "consolidated ZDR:\n",
      "means there's a kdp problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwilson41\\AppData\\Local\\Continuum\\Anaconda3\\envs\\radar\\lib\\site-packages\\ipykernel_launcher.py:641: DeprecationWarning: assignment will raise an error in the future, most likely because your index result shape does not match the value array shape. You can use `arr.flat[index] = values` to keep the old behaviour.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure saved\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "0.451157\n",
      "2017-07-11 23:03:44.648000\n",
      "its this line\n",
      "heres the problem\n",
      "almost gridding\n",
      "made it to smoothing\n",
      "made it through gradient\n",
      "got gradient\n",
      "Set up our projection\n",
      "(-98.825555555555553, 46.027777777777779, <cartopy.crs.PlateCarree object at 0x00000205005C1570>)\n",
      "plotting\n",
      "1\n",
      "-98.29758779304682\n",
      "past mask\n",
      "46.6345\n",
      "found a storm\n",
      "[ 79.03234214  87.38287542  88.19728533  76.97929891  69.91200187\n",
      "  76.02199085]\n",
      "Poly lon -98.29758779304682\n",
      "[-97.22237017 -97.10865281 -97.67879498 -97.45310833 -97.57895392\n",
      " -97.34862643]\n",
      "[0 0 1 2 2 3]\n",
      "storm id 2\n",
      "added polygon\n",
      "1\n",
      "-97.20710220619983\n",
      "past mask\n",
      "46.2326\n",
      "found a storm\n",
      "[  1.16975577   7.25354768  82.88867168  48.51726789  53.01064723\n",
      "  31.39639063]\n",
      "Poly lon -97.20710220619983\n",
      "[-97.22237017 -97.10865281 -97.67879498 -97.45310833 -97.57895392\n",
      " -97.34862643]\n",
      "[0 0 1 2 2 3]\n",
      "storm id 0\n",
      "added polygon\n",
      "1\n",
      "-97.66653154894973\n",
      "past mask\n",
      "48.8213\n",
      "found a storm\n",
      "[ 82.166674    86.61202835   1.02019859  34.50294373  30.97322009\n",
      "  51.71483468]\n",
      "Poly lon -97.66653154894973\n",
      "[-97.22237017 -97.10865281 -97.67879498 -97.45310833 -97.57895392\n",
      " -97.34862643]\n",
      "[0 0 1 2 2 3]\n",
      "storm id 1\n",
      "added polygon\n",
      "1\n",
      "-97.39943500899493\n",
      "past mask\n",
      "48.0497\n",
      "found a storm\n",
      "found a big storm\n",
      "plotted a big storm\n",
      "made it to beginning of loop\n",
      "2\n",
      "-97.46584740157215\n",
      "[ 48.38024478  52.80504945  33.8561514    0.97818298   8.38107555\n",
      "  17.88068421]\n",
      "Poly lon -97.46584740157215\n",
      "[-97.22237017 -97.10865281 -97.67879498 -97.45310833 -97.57895392\n",
      " -97.34862643]\n",
      "[0 0 1 2 2 3]\n",
      "storm id 2\n",
      "added polygon\n",
      "2\n",
      "-97.3468318900864\n",
      "[ 30.40975261  34.61002712  52.05307547  17.53161555  23.49420613\n",
      "   0.3188595 ]\n",
      "Poly lon -97.3468318900864\n",
      "[-97.22237017 -97.10865281 -97.67879498 -97.45310833 -97.57895392\n",
      " -97.34862643]\n",
      "[0 0 1 2 2 3]\n",
      "storm id 3\n",
      "added polygon\n",
      "made it here\n",
      "made it through zdr centroids\n",
      "1\n",
      "-97.23662910006796\n",
      "1\n",
      "-97.71739904997541\n",
      "[ 87.19817725  84.59295508   3.78948301  35.72604137  53.91084861]\n",
      "1\n",
      "-97.4960275663581\n",
      "[ 74.13909265  49.34477224  33.61371953   2.35796851  18.76699406]\n",
      "1\n",
      "-97.37035757053698\n",
      "1\n",
      "-97.35945119843717\n",
      "[ 75.10384755  31.23708143  51.7690793   17.92137649   0.94839435]\n",
      "made it through kdp centroids\n",
      "0\n",
      "1\n",
      "2\n",
      "-97.4658474016\n",
      "[ 70.37703022   7.45362657]\n",
      "[ 183.06420089]\n",
      "3\n",
      "calculating separation\n",
      "Boolean problem here\n",
      "maybe its here\n",
      "or not\n",
      "(0, -98.297587793046816)\n",
      "[]\n",
      "(1, -97.207102206199835)\n",
      "[]\n",
      "(2, -97.666531548949735)\n",
      "[0]\n",
      "(3, -97.465847401572148)\n",
      "[1]\n",
      "(4, -97.346831890086406)\n",
      "[]\n",
      "made it through giant if statement\n",
      "plotted centroids\n",
      "making dataframe\n",
      "setting index\n",
      "made it to plotting\n",
      "consolidated ZDR:\n",
      "consolidated ZDR:\n",
      "means there's a kdp problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwilson41\\AppData\\Local\\Continuum\\Anaconda3\\envs\\radar\\lib\\site-packages\\ipykernel_launcher.py:641: DeprecationWarning: assignment will raise an error in the future, most likely because your index result shape does not match the value array shape. You can use `arr.flat[index] = values` to keep the old behaviour.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure saved\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "0.447231\n",
      "2017-07-11 23:05:50.276000\n",
      "its this line\n",
      "heres the problem\n",
      "almost gridding\n",
      "made it to smoothing\n",
      "made it through gradient\n",
      "got gradient\n",
      "Set up our projection\n",
      "(-98.825555555555553, 46.027777777777779, <cartopy.crs.PlateCarree object at 0x00000205053D9150>)\n",
      "plotting\n",
      "1\n",
      "-98.26336410971045\n",
      "past mask\n",
      "46.9576\n",
      "found a storm\n",
      "[  2.52090732  77.63617764  87.61514892  74.25899094  73.64603097]\n",
      "Poly lon -98.26336410971045\n",
      "[-98.29758779 -97.20710221 -97.66653155 -97.4658474  -97.34683189]\n",
      "[4 0 1 2 3]\n",
      "storm id 4\n",
      "added polygon\n",
      "1\n",
      "-97.18927324220441\n",
      "past mask\n",
      "45.2362\n",
      "1\n",
      "-97.64841926581131\n",
      "past mask\n",
      "48.9814\n",
      "found a storm\n",
      "found a big storm\n",
      "plotted a big storm\n",
      "made it to beginning of loop\n",
      "2\n",
      "-97.68613365797674\n",
      "[ 89.22462211  84.49620226   1.80649822  35.45463698  53.65002537]\n",
      "Poly lon -97.68613365797674\n",
      "[-98.29758779 -97.20710221 -97.66653155 -97.4658474  -97.34683189]\n",
      "[4 0 1 2 3]\n",
      "storm id 1\n",
      "added polygon\n",
      "1\n",
      "-97.41537577009055\n",
      "past mask\n",
      "48.4434\n",
      "found a storm\n",
      "found a big storm\n",
      "plotted a big storm\n",
      "made it to beginning of loop\n",
      "2\n",
      "-97.45222812921368\n",
      "[ 77.29555498  48.90608392  34.13938015   1.02641718  17.90179729]\n",
      "Poly lon -97.45222812921368\n",
      "[-98.29758779 -97.20710221 -97.66653155 -97.4658474  -97.34683189]\n",
      "[4 0 1 2 3]\n",
      "storm id 2\n",
      "added polygon\n",
      "1\n",
      "-97.32939147356427\n",
      "past mask\n",
      "47.0393\n",
      "found a storm\n",
      "[ 77.33712006  30.97690664  52.36036471  18.59293163   1.32620943]\n",
      "Poly lon -97.32939147356427\n",
      "[-98.29758779 -97.20710221 -97.66653155 -97.4658474  -97.34683189]\n",
      "[4 0 1 2 3]\n",
      "storm id 3\n",
      "added polygon\n",
      "made it here\n",
      "made it through zdr centroids\n",
      "1\n",
      "-97.70393169392229\n",
      "[ 85.75855232   2.09875543  35.04198211  53.25887341]\n",
      "1\n",
      "-97.4791639478693\n",
      "[ 73.11356773  35.54621309   2.14455055  18.66158193]\n",
      "1\n",
      "-97.3692394029251\n",
      "1\n",
      "-97.42915832468708\n",
      "[ 67.90894642  51.53287124  16.70073817   7.41582132]\n",
      "1\n",
      "-97.34096565385387\n",
      "[ 73.97161444  54.01141716  18.25305119   0.98598042]\n",
      "1\n",
      "-97.3818688550111\n",
      "made it through kdp centroids\n",
      "0\n",
      "1\n",
      "2\n",
      "-97.4522281292\n",
      "[ 82.59897011   7.29071738]\n",
      "[ 173.31479445]\n",
      "3\n",
      "calculating separation\n",
      "Boolean problem here\n",
      "maybe its here\n",
      "or not\n",
      "(0, -98.263364109710452)\n",
      "[]\n",
      "(1, -97.68613365797674)\n",
      "[0]\n",
      "(2, -97.45222812921368)\n",
      "[1]\n",
      "(3, -97.329391473564272)\n",
      "[]\n",
      "made it through giant if statement\n",
      "plotted centroids\n",
      "making dataframe\n",
      "setting index\n",
      "made it to plotting\n",
      "consolidated ZDR:\n",
      "consolidated ZDR:\n",
      "means there's a kdp problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwilson41\\AppData\\Local\\Continuum\\Anaconda3\\envs\\radar\\lib\\site-packages\\ipykernel_launcher.py:641: DeprecationWarning: assignment will raise an error in the future, most likely because your index result shape does not match the value array shape. You can use `arr.flat[index] = values` to keep the old behaviour.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure saved\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "0.446022\n",
      "2017-07-11 23:07:50.356000\n",
      "its this line\n",
      "heres the problem\n",
      "almost gridding\n",
      "made it to smoothing\n",
      "made it through gradient\n",
      "got gradient\n",
      "Set up our projection\n",
      "(-98.825555555555553, 46.027777777777779, <cartopy.crs.PlateCarree object at 0x00000205053D90F8>)\n",
      "plotting\n",
      "1\n",
      "-98.2446142524504\n",
      "past mask\n",
      "46.8759\n",
      "found a storm\n",
      "[  1.40091349  86.93555189  73.92210878  73.58544616]\n",
      "Poly lon -98.2446142524504\n",
      "[-98.26336411 -97.68613366 -97.45222813 -97.32939147]\n",
      "[4 1 2 3]\n",
      "storm id 4\n",
      "added polygon\n",
      "1\n",
      "-97.1568484283618\n",
      "past mask\n",
      "nan\n",
      "1\n",
      "-97.62682151488447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwilson41\\AppData\\Local\\Continuum\\Anaconda3\\envs\\radar\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2889: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\mwilson41\\AppData\\Local\\Continuum\\Anaconda3\\envs\\radar\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past mask\n",
      "48.8179\n",
      "found a storm\n",
      "found a big storm\n",
      "plotted a big storm\n",
      "made it to beginning of loop\n",
      "2\n",
      "-97.68510128623059\n",
      "[ 87.75532188   0.14219776  35.62698512  53.85414867]\n",
      "Poly lon -97.68510128623059\n",
      "[-98.26336411 -97.68613366 -97.45222813 -97.32939147]\n",
      "[4 1 2 3]\n",
      "storm id 1\n",
      "added polygon\n",
      "1\n",
      "-97.39009350849176\n",
      "past mask\n",
      "48.2892\n",
      "found a storm\n",
      "found a big storm\n",
      "plotted a big storm\n",
      "made it to beginning of loop\n",
      "2\n",
      "-97.46597219043979\n",
      "[ 73.95494935  35.88095986   1.22041999  18.19252474]\n",
      "Poly lon -97.46597219043979\n",
      "[-98.26336411 -97.68613366 -97.45222813 -97.32939147]\n",
      "[4 1 2 3]\n",
      "storm id 2\n",
      "added polygon\n",
      "2\n",
      "-97.30982613135299\n",
      "nope\n",
      "1\n",
      "-97.3320791755104\n",
      "past mask\n",
      "46.7177\n",
      "found a storm\n",
      "[ 74.54191315  54.39745599  18.62949341   0.6047426 ]\n",
      "Poly lon -97.3320791755104\n",
      "[-98.26336411 -97.68613366 -97.45222813 -97.32939147]\n",
      "[4 1 2 3]\n",
      "storm id 3\n",
      "added polygon\n",
      "made it here\n",
      "made it through zdr centroids\n",
      "1\n",
      "-97.68955298695802\n",
      "[ 85.53391602   1.37601598  34.71206613  53.25213303]\n",
      "1\n",
      "-97.47366640820388\n",
      "[ 72.10276976  35.70708163   0.62250422  18.66525894]\n",
      "1\n",
      "-97.30508977950642\n",
      "[ 82.68580477  42.1616612   11.93031355  16.32525286]\n",
      "1\n",
      "-97.36963031792062\n",
      "[ 70.29323788  53.72685777  18.01528494   2.90039218]\n",
      "made it through kdp centroids\n",
      "0\n",
      "1\n",
      "2\n",
      "-97.4659721904\n",
      "[ 46.85453952]\n",
      "[ 131.41546309    5.71460393]\n",
      "calculating separation\n",
      "Boolean problem here\n",
      "maybe its here\n",
      "or not\n",
      "(0, -98.244614252450404)\n",
      "[]\n",
      "(1, -97.685101286230591)\n",
      "[0]\n",
      "(2, -97.465972190439786)\n",
      "[1]\n",
      "(3, -97.332079175510401)\n",
      "[]\n",
      "made it through giant if statement\n",
      "plotted centroids\n",
      "making dataframe\n",
      "setting index\n",
      "made it to plotting\n",
      "consolidated ZDR:\n",
      "consolidated ZDR:\n",
      "means there's a kdp problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwilson41\\AppData\\Local\\Continuum\\Anaconda3\\envs\\radar\\lib\\site-packages\\ipykernel_launcher.py:641: DeprecationWarning: assignment will raise an error in the future, most likely because your index result shape does not match the value array shape. You can use `arr.flat[index] = values` to keep the old behaviour.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure saved\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "0.451015\n",
      "2017-07-11 23:09:43.799000\n",
      "its this line\n",
      "heres the problem\n",
      "almost gridding\n",
      "made it to smoothing\n",
      "made it through gradient\n",
      "got gradient\n",
      "Set up our projection\n",
      "(-98.825555555555553, 46.027777777777779, <cartopy.crs.PlateCarree object at 0x00000205053D9200>)\n",
      "plotting\n",
      "1\n",
      "-98.23587680599688\n",
      "past mask\n",
      "46.2283\n",
      "found a storm\n",
      "[  0.64864618  86.48019232  72.14144206  72.54688819]\n",
      "Poly lon -98.23587680599688\n",
      "[-98.24461425 -97.68510129 -97.46597219 -97.33207918]\n",
      "[4 1 2 3]\n",
      "storm id 4\n",
      "added polygon\n",
      "1\n",
      "-97.61599698309801\n",
      "past mask\n",
      "48.3339\n",
      "found a storm\n",
      "found a big storm\n",
      "plotted a big storm\n",
      "made it to beginning of loop\n",
      "2\n",
      "-97.67367081696723\n",
      "[ 87.66019221   0.95921583  35.75871397  54.24172864]\n",
      "Poly lon -97.67367081696723\n",
      "[-98.24461425 -97.68510129 -97.46597219 -97.33207918]\n",
      "[4 1 2 3]\n",
      "storm id 1\n",
      "added polygon\n",
      "1\n",
      "-97.52909466315916\n",
      "past mask\n",
      "45.0164\n",
      "1\n",
      "-97.37014827049656\n",
      "past mask\n",
      "47.7599\n",
      "found a storm\n",
      "found a big storm\n",
      "plotted a big storm\n",
      "made it to beginning of loop\n",
      "2\n",
      "-97.46760206341\n",
      "[ 72.22792827  36.24010322   0.63399439  18.10594445]\n",
      "Poly lon -97.46760206341\n",
      "[-98.24461425 -97.68510129 -97.46597219 -97.33207918]\n",
      "[4 1 2 3]\n",
      "storm id 2\n",
      "added polygon\n",
      "made it here\n",
      "made it through zdr centroids\n",
      "1\n",
      "-97.69342547711027\n",
      "[ 86.47827047   1.47654688  36.8076281 ]\n",
      "1\n",
      "-97.6547122670903\n",
      "[ 84.97990892   3.6947453   32.57847847]\n",
      "1\n",
      "-97.47440416497612\n",
      "[ 71.10774443  36.2919757    0.56487347]\n",
      "1\n",
      "-97.29954156717635\n",
      "1\n",
      "-97.32222726503383\n",
      "1\n",
      "-97.32222625811981\n",
      "made it through kdp centroids\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "-97.4676020634\n",
      "[ 13.90598214]\n",
      "[ 111.78747652]\n",
      "calculating separation\n",
      "Boolean problem here\n",
      "maybe its here\n",
      "or not\n",
      "(0, -98.235876805996881)\n",
      "[]\n",
      "(1, -97.673670816967231)\n",
      "[0]\n",
      "(2, -97.467602063409998)\n",
      "[1]\n",
      "made it through giant if statement\n",
      "plotted centroids\n",
      "making dataframe\n",
      "setting index\n",
      "made it to plotting\n",
      "consolidated ZDR:\n",
      "consolidated ZDR:\n",
      "means there's a kdp problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwilson41\\AppData\\Local\\Continuum\\Anaconda3\\envs\\radar\\lib\\site-packages\\ipykernel_launcher.py:641: DeprecationWarning: assignment will raise an error in the future, most likely because your index result shape does not match the value array shape. You can use `arr.flat[index] = values` to keep the old behaviour.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure saved\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n",
      "in loop\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "#Set angle perpendicular to FFD Z gradient\n",
    "storm_relative_dir = 180\n",
    "srdir = storm_relative_dir\n",
    "query = rs.query()\n",
    "#Here, set the initial time of the archived radar loop you want.\n",
    "dt = datetime(2017,7, 11, 23, 0)\n",
    "station = 'KMVX'\n",
    "#Set loop duration\n",
    "query.stations(station).time_range(dt, dt + timedelta(hours=.1))\n",
    "cat = rs.get_catalog(query)\n",
    "cat.datasets\n",
    "f = 27\n",
    "n = 1\n",
    "storm_index = 0\n",
    "scan_index = 0\n",
    "g = Geod(ellps='sphere')\n",
    "for item in sorted(cat.datasets.items()):\n",
    "    # After looping over the list of sorted datasets, pull the actual Dataset object out\n",
    "    # of our list of items and access over CDMRemote\n",
    "    try:\n",
    "        ds = item[1]\n",
    "        radar1 = pyart.io.nexrad_cdm.read_nexrad_cdm(ds.access_urls['OPENDAP'])\n",
    "        #Now let's calculate and plot specific differential phase.\n",
    "        #Pre-SAILS # for below: 17\n",
    "        #SAILS #: 25\n",
    "        if radar1.nsweeps > 25:\n",
    "            continue\n",
    "        for i in range(radar1.nsweeps):\n",
    "            print('in loop')\n",
    "            print(radar1.nsweeps)\n",
    "            radar = radar1.extract_sweeps([i])\n",
    "            if ((np.mean(radar.elevation['data']) < .65) and (np.max(np.asarray(radar.fields['differential_reflectivity']['data'])) != np.min(np.asarray(radar.fields['differential_reflectivity']['data'])))):\n",
    "                n = n+1\n",
    "                print(np.mean(radar.elevation['data']))\n",
    "                time_start = netCDF4.num2date(radar.time['data'][0], radar.time['units'])\n",
    "                print(time_start)\n",
    "                kdp_dict = pyart.retrieve.kdp_proc.kdp_maesaka(radar)\n",
    "                print('its this line')\n",
    "                radar.add_field('KDP', kdp_dict[0])\n",
    "                print('heres the problem')\n",
    "                # mask out last 10 gates of each ray, this removes the \"ring\" around the radar.\n",
    "                radar.fields['differential_reflectivity']['data'][:, -10:] = np.ma.masked\n",
    "                ref_ungridded = radar.fields['reflectivity']['data']\n",
    "                refl_c = np.copy(ref_ungridded)\n",
    "                ref_c = ma.masked_where(refl_c < 20., refl_c)\n",
    "                #Get ungridded ZDR\n",
    "                zdr_ungridded = radar.fields['differential_reflectivity']['data']\n",
    "                zdrl_c = np.copy(zdr_ungridded)\n",
    "                zdr_c = ma.masked_where(refl_c < 20, zdrl_c)\n",
    "\n",
    "                ungrid_lons = radar.gate_longitude['data']\n",
    "                ungrid_lats = radar.gate_latitude['data']\n",
    "                # exclude masked gates from the gridding\n",
    "                gatefilter = pyart.filters.GateFilter(radar)\n",
    "                gatefilter.exclude_masked('differential_reflectivity')\n",
    "                print('almost gridding')\n",
    "                #Now let's grid the data\n",
    "                grid = pyart.map.grid_from_radars(\n",
    "                    (radar,), gatefilters=(gatefilter, ),\n",
    "                    grid_shape=(1, 500, 500),\n",
    "                    grid_limits=((200, 200), (-123000.0, 123000.0), (-123000.0, 123000.0)),\n",
    "                    fields=['differential_reflectivity','reflectivity','KDP','cross_correlation_ratio'])\n",
    "                #Get gate altitudes\n",
    "                gate_altitude = radar.gate_altitude['data'][:]\n",
    "                #Get the data from the grid\n",
    "                ZDR = grid.fields['differential_reflectivity']['data'][0]\n",
    "                REF = grid.fields['reflectivity']['data'][0]\n",
    "                KDP = grid.fields['KDP']['data'][0]\n",
    "                CC = grid.fields['cross_correlation_ratio']['data'][0]\n",
    "\n",
    "                #Mask everything below 20dbz\n",
    "                #import numpy.ma as ma\n",
    "                ZDRmasked1 = ma.masked_where(REF < 20, ZDR)\n",
    "                REFmasked = ma.masked_where(REF < 20, REF)\n",
    "                #Use a 45 dBZ mask for KDP to only get areas in the storm core\n",
    "                KDPmasked = ma.masked_where(REF < 50, KDP)\n",
    "                KDPmasked = ma.filled(KDPmasked, fill_value = -2)\n",
    "                #Filter out spots not in forward flank using gradient direction\n",
    "                print('made it to smoothing')\n",
    "                smoothed_ref1 = ndi.gaussian_filter(REFmasked, sigma = 2, order = 0)\n",
    "                REFgradient = np.asarray(np.gradient(smoothed_ref1))\n",
    "                REFgradient[0,:,:] = ma.masked_where(REF < 20, REFgradient[0,:,:])\n",
    "                REFgradient[1,:,:] = ma.masked_where(REF < 20, REFgradient[1,:,:])\n",
    "                print('made it through gradient')\n",
    "                grad_dir1 = get_wind_dir(REFgradient[1,:,:] * units('m/s'), REFgradient[0,:,:] * units('m/s'))\n",
    "                grad_dir = ma.masked_where(REF < 20, grad_dir1)\n",
    "                #srdir = storm_relative_dir\n",
    "                grad_ffd = np.abs(np.arctan2(np.sin(grad_dir * units('degrees')-srdir * units('degrees')), np.cos(grad_dir * units('degrees')-srdir * units('degrees'))))\n",
    "                grad_ffd = grad_ffd.to('degrees')\n",
    "                print('got gradient')\n",
    "                #Add a fill value for the ZDR mask so that contours will be closed\n",
    "                ZDRmasked2 = ma.masked_where(grad_ffd > 120 * units('degrees'), ZDRmasked1)\n",
    "                ZDRmasked = ma.masked_where(CC < .60, ZDRmasked2)\n",
    "                ZDRmasked = ma.filled(ZDRmasked, fill_value = -2)\n",
    "\n",
    "                rlons = grid.point_longitude['data']\n",
    "                rlats = grid.point_latitude['data']\n",
    "                rlons_2d = rlons[0,:,:]\n",
    "                rlats_2d = rlats[0,:,:]\n",
    "                cenlat = radar.latitude['data'][0]\n",
    "                cenlon = radar.longitude['data'][0]\n",
    "                #Let's set up the map projection!\n",
    "                print('Set up our projection')\n",
    "                crs = ccrs.LambertConformal(central_longitude=-100.0, central_latitude=45.0)\n",
    "\n",
    "                # Set up our array of latitude and longitude values and transform to \n",
    "                # the desired projection.\n",
    "\n",
    "                tlatlons = crs.transform_points(ccrs.LambertConformal(central_longitude=265, central_latitude=25, standard_parallels=(25.,25.)),rlons[0,:,:],rlats[0,:,:])\n",
    "                tlons = tlatlons[:,:,0]\n",
    "                tlats = tlatlons[:,:,1]\n",
    "\n",
    "                # Limit the extent of the map area, must convert to proper coords.\n",
    "                LL = (cenlon-1.5,cenlat-1.5,ccrs.PlateCarree())\n",
    "                UR = (cenlon+1.5,cenlat+1.5,ccrs.PlateCarree())\n",
    "                print(LL)\n",
    "\n",
    "                # Get data to plot state and province boundaries\n",
    "                states_provinces = cfeature.NaturalEarthFeature(\n",
    "                        category='cultural',\n",
    "                        name='admin_1_states_provinces_lakes',\n",
    "                        scale='50m',\n",
    "                        facecolor='none')\n",
    "                fname = 'cb_2016_us_county_20m/cb_2016_us_county_20m.shp'\n",
    "                fname2 = 'cb_2016_us_state_20m/cb_2016_us_state_20m.shp'\n",
    "                counties = ShapelyFeature(Reader(fname).geometries(),ccrs.PlateCarree(), facecolor = 'none', edgecolor = 'black')\n",
    "                states = ShapelyFeature(Reader(fname2).geometries(),ccrs.PlateCarree(), facecolor = 'none', edgecolor = 'black')\n",
    "                fig=plt.figure(n,figsize=(30.,25.))\n",
    "                ax = plt.subplot(111,projection=ccrs.PlateCarree())\n",
    "                ax.coastlines('50m',edgecolor='black',linewidth=0.75)\n",
    "                #ax.add_feature(states_provinces,edgecolor='black',linewidth=0.5)\n",
    "                ax.add_feature(counties, edgecolor = 'black', linewidth = 0.5)\n",
    "                ax.add_feature(states, edgecolor = 'black', linewidth = 1.5)\n",
    "                ax.set_extent([LL[0],UR[0],LL[1],UR[1]])\n",
    "                REFlevels = np.arange(20,73,2)\n",
    "                print('plotting')\n",
    "                #ax.contourf(rlons[0,:,:],rlats[0,:,:],REFmasked,REFlevels,cmap = plt.cm.gist_ncar)\n",
    "                refp = ax.pcolormesh(ungrid_lons, ungrid_lats, ref_c, cmap=plt.cm.gist_ncar, vmin = 10, vmax = 73)\n",
    "                #zdrp = ax.pcolormesh(ungrid_lons, ungrid_lats, zdr_c, cmap=plt.cm.nipy_spectral, vmin = -2, vmax = 6)\n",
    "                #Plot local maxes in reflectivity\n",
    "                # image_max is the dilation of im with a 20*20 structuring element\n",
    "                # It is used within peak_local_max function\n",
    "                smoothed_ref = ndi.gaussian_filter(REFmasked, sigma = 3, order = 0)\n",
    "                #image_max = ndi.maximum_filter(smoothed_ref, size=15, mode='constant')\n",
    "\n",
    "                # Comparison between image_max and im to find the coordinates of local maxima\n",
    "                #coordinates = peak_local_max(smoothed_ref, min_distance=20)\n",
    "                #ref_maxes = REFmasked[coordinates[:,0], coordinates[:,1]]\n",
    "                #max_lons = rlons[0,coordinates[:,0], coordinates[:,1]]\n",
    "                #max_lats = rlats[0,coordinates[:,0], coordinates[:,1]]\n",
    "                #max_lons_c = max_lons[ref_maxes > 45]\n",
    "                #max_lats_c = max_lats[ref_maxes > 45]\n",
    "                \n",
    "                REFlev = [45]\n",
    "                REFlev1 = [50]\n",
    "                refc = ax.contour(rlons[0,:,:],rlats[0,:,:],smoothed_ref,REFlev, alpha=.01)\n",
    "\n",
    "                ref_areas = []\n",
    "                max_lons_c = []\n",
    "                max_lats_c = []\n",
    "                storm_ids = []\n",
    "                \n",
    "                proj = partial(pyproj.transform, pyproj.Proj(init='epsg:4326'),\n",
    "                           pyproj.Proj(init='epsg:3857'))\n",
    "\n",
    "                #Look for reflectivity centroids\n",
    "                for col in refc.collections:\n",
    "                    # Loop through all polygons that have the same intensity level\n",
    "                    for contour_path in col.get_paths(): \n",
    "                        # Create the polygon for this intensity level\n",
    "                        # The first polygon in the path is the main one, the following ones are \"holes\"\n",
    "                        for ncp,cp in enumerate(contour_path.to_polygons()):\n",
    "                            print(1)\n",
    "                            cpa = np.asarray(cp[:])\n",
    "                            x = cpa[:,0]\n",
    "                            y = cpa[:,1]\n",
    "                            new_shape = geometry.Polygon([(i[0], i[1]) for i in zip(x,y)])\n",
    "                            if ncp == 0:\n",
    "                                poly = new_shape\n",
    "                            else:\n",
    "                                # Remove the holes if there are any\n",
    "                                poly = poly.difference(new_shape)\n",
    "\n",
    "                        # do something with polygon\n",
    "                        #print(poly.area) \n",
    "                        print(poly.centroid.x)\n",
    "                        s_new = transform(proj, poly)\n",
    "                        projected_area = (transform(proj, poly).area * units('m^2')).to('km^2')\n",
    "                        boundary = np.asarray(poly.boundary.xy)\n",
    "                        polypath = Path(boundary.transpose())\n",
    "                        coord_map = np.vstack((rlons[0,:,:].flatten(), rlats[0,:,:].flatten())).T # create an Mx2 array listing all the coordinates in field\n",
    "                        maskr = polypath.contains_points(coord_map).reshape(rlons[0,:,:].shape)\n",
    "                        meanr = np.mean(smoothed_ref[maskr])\n",
    "                        print('past mask')\n",
    "                        print(meanr)\n",
    "                        if projected_area > 10 * units('km^2') and meanr > REFlev[0]:\n",
    "                            print('found a storm')\n",
    "                            #For big blobs with embedded supercells, find the embedded storm cores\n",
    "                            #Normal 'big storm' cutoff 300 km^2\n",
    "                            if projected_area > 300 * units('km^2'):\n",
    "                                print('found a big storm')\n",
    "                                rlon_2 = rlons[0,:,:]\n",
    "                                rlat_2 = rlats[0,:,:]\n",
    "                                #smoothed_ref_m = ma.MaskedArray(smoothed_ref, mask=maskr)\n",
    "                                smoothed_ref_m = ma.masked_where(maskr==False, smoothed_ref)\n",
    "                                smoothed_ref_m = ma.filled(smoothed_ref_m, fill_value = -2)\n",
    "                                rlon2m = ma.MaskedArray(rlon_2, mask=maskr)\n",
    "                                rlat2m = ma.MaskedArray(rlat_2, mask=maskr)\n",
    "                                refc1 = ax.contour(rlon2m,rlat2m,smoothed_ref_m,REFlev1, linewidths = 3, linestyle = '--', alpha=.01)\n",
    "                                #refc1 = ax.contour(rlon_2[maskr],rlat_2[maskr],smoothed_ref[maskr],REFlev1, colors = 'g', linewidths = 3)\n",
    "                                print('plotted a big storm')\n",
    "                                #Look for reflectivity centroids\n",
    "                                for col1 in refc1.collections:\n",
    "                                    # Loop through all polygons that have the same intensity level\n",
    "                                    print('made it to beginning of loop')\n",
    "                                    for contour_path1 in col1.get_paths(): \n",
    "                                        # Create the polygon for this intensity level\n",
    "                                        # The first polygon in the path is the main one, the following ones are \"holes\"\n",
    "                                        for ncp1,cp1 in enumerate(contour_path1.to_polygons()):\n",
    "                                            print(2)\n",
    "                                            cpa1 = np.asarray(cp1[:])\n",
    "                                            x1 = cpa1[:,0]\n",
    "                                            y1 = cpa1[:,1]\n",
    "                                            new_shape1 = geometry.Polygon([(i[0], i[1]) for i in zip(x1,y1)])\n",
    "                                            if ncp1 == 0:\n",
    "                                                poly1 = new_shape1\n",
    "                                            else:\n",
    "                                                # Remove the holes if there are any\n",
    "                                                poly1 = poly1.difference(new_shape)\n",
    "\n",
    "                                        # do something with polygon\n",
    "                                        #print(poly.area) \n",
    "                                        print(poly1.centroid.x)\n",
    "                                        s_new1 = transform(proj, poly1)\n",
    "                                        projected_area1 = (transform(proj, poly1).area * units('m^2')).to('km^2')\n",
    "                                        if projected_area1 > 10 * units('km^2'):\n",
    "                                            ref_areas.append((projected_area1*2))\n",
    "                                            max_lons_c.append((poly1.centroid.x))\n",
    "                                            max_lats_c.append((poly1.centroid.y))\n",
    "                                            if scan_index == 0:\n",
    "                                                storm_ids.append((storm_index))\n",
    "                                                storm_index = storm_index + 1\n",
    "                                            else:\n",
    "                                                #dist_track = np.zeros((np.asarray(max_lons_p).shape[0]))\n",
    "                                                max_lons_p = np.asarray(tracks_dataframe['storm_lon'].loc[scan_index-1].iloc[:])\n",
    "                                                max_lats_p = np.asarray(tracks_dataframe['storm_lat'].loc[scan_index-1].iloc[:])\n",
    "                                                storm_ids_p = np.asarray(tracks_dataframe['storm_id1'].loc[scan_index-1].iloc[:])\n",
    "                                                dist_track = np.zeros((np.asarray(max_lons_p).shape[0]))\n",
    "                                                for i in range(max_lons_p.shape[0]):\n",
    "                                                    distance_track = g.inv(poly1.centroid.x, poly1.centroid.y,\n",
    "                                                                           max_lons_p[i], max_lats_p[i])\n",
    "                                                    dist_track[i] = distance_track[2]/1000.\n",
    "                                                print(dist_track)\n",
    "                                                print('Poly lon', poly1.centroid.x)\n",
    "                                                print(max_lons_p)\n",
    "                                                print(storm_ids_p)\n",
    "                                                if np.min(dist_track) < 10.0:\n",
    "                                                    storm_ids.append((storm_ids_p[np.where(dist_track == np.min(dist_track))[0][0]]))\n",
    "                                                    print('storm id', storm_ids_p[np.where(dist_track == np.min(dist_track))[0][0]])\n",
    "                                                else:\n",
    "                                                    storm_ids.append((storm_index))\n",
    "                                                    print('storm id', storm_ids_p[np.where(dist_track == np.min(dist_track))[0][0]])\n",
    "                                                    storm_index = storm_index + 1\n",
    "                                            print('added polygon')\n",
    "                                        else:\n",
    "                                            print('nope')\n",
    "                            else:\n",
    "                                ref_areas.append((projected_area))\n",
    "                                max_lons_c.append((poly.centroid.x))\n",
    "                                max_lats_c.append((poly.centroid.y))\n",
    "                                if scan_index == 0:\n",
    "                                    storm_ids.append((storm_index))\n",
    "                                    storm_index = storm_index + 1\n",
    "                                else:\n",
    "                                    #dist_track = np.zeros((np.asarray(max_lons_p).shape[0]))\n",
    "                                    max_lons_p = np.asarray(tracks_dataframe['storm_lon'].loc[scan_index-1].iloc[:])\n",
    "                                    max_lats_p = np.asarray(tracks_dataframe['storm_lat'].loc[scan_index-1].iloc[:])\n",
    "                                    storm_ids_p = np.asarray(tracks_dataframe['storm_id1'].loc[scan_index-1].iloc[:])\n",
    "                                    dist_track = np.zeros((np.asarray(max_lons_p).shape[0]))\n",
    "                                    for i in range(max_lons_p.shape[0]):\n",
    "                                        distance_track = g.inv(poly.centroid.x, poly.centroid.y,\n",
    "                                                               max_lons_p[i], max_lats_p[i])\n",
    "                                        dist_track[i] = distance_track[2]/1000.\n",
    "                                    print(dist_track)\n",
    "                                    print('Poly lon', poly.centroid.x)\n",
    "                                    print(max_lons_p)\n",
    "                                    print(storm_ids_p)\n",
    "                                    if np.min(dist_track) < 10.0:\n",
    "                                        storm_ids.append((storm_ids_p[np.where(dist_track == np.min(dist_track))[0][0]]))\n",
    "                                        print('storm id', storm_ids_p[np.where(dist_track == np.min(dist_track))[0][0]])\n",
    "                                    else:\n",
    "                                        storm_ids.append((storm_index))\n",
    "                                        print('storm id', storm_ids_p[np.where(dist_track == np.min(dist_track))[0][0]])\n",
    "                                        storm_index = storm_index + 1\n",
    "                                print('added polygon')\n",
    "                                            \n",
    "                    #print(s_new)\n",
    "                max_lons_c = np.asarray(max_lons_c)\n",
    "                max_lats_c = np.asarray(max_lats_c)\n",
    "                #ZDRlevels = np.arange(3, np.max(ZDRmasked)+((np.max(ZDRmasked))-3)/2, (np.max(ZDRmasked))-3)\n",
    "                zdrlev = [3.5]\n",
    "                kdplev = [.75]\n",
    "                #ZDRlevels = np.arange(3,5.5,.5)\n",
    "                #ZDRlevels1 = np.arange(5,10,.5)\n",
    "                #KDPlevels = np.arange(.75, np.max(KDPmasked)+((np.max(KDPmasked))-1.5)/2, (np.max(KDPmasked))-1.5)\n",
    "                #KDPlevels = np.arange(.75,1.75,.25)\n",
    "                #KDPlevels1 = np.arange(1.5,10,.25)\n",
    "                zdrc = ax.contour(rlons[0,:,:],rlats[0,:,:],ZDRmasked,zdrlev,linewidths = 2, colors='purple', alpha = .01)\n",
    "                #zrdc = ax.contourf(rlons[0,:,:],rlats[0,:,:],ZDRmasked,ZDRlevels,linewide = .01, colors='pink', alpha = .8)\n",
    "                #ax.contourf(rlons[0,:,:],rlats[0,:,:],ZDRmasked,ZDRlevels1,linewide = .01, colors='crimson', alpha = .8)\n",
    "\n",
    "                #kdpc = ax.contourf(rlons[0,:,:],rlats[0,:,:],KDPmasked,KDPlevels,linewide = .01, colors ='green', alpha = .5)\n",
    "                kdpc = ax.contour(rlons[0,:,:],rlats[0,:,:],KDPmasked,kdplev,linewidths = 2, colors='green', alpha = .8)\n",
    "                #ax.contourf(rlons[0,:,:],rlats[0,:,:],KDPmasked,KDPlevels1,linewide = .01, colors ='b', alpha = .5)\n",
    "                print('made it here')\n",
    "                plt.savefig('testfig.png')\n",
    "\n",
    "                #proj = partial(pyproj.transform, pyproj.Proj(init='epsg:4326'),\n",
    "                #           pyproj.Proj(init='epsg:3857'))\n",
    "                zdr_areas = []\n",
    "                zdr_centroid_lon = []\n",
    "                zdr_centroid_lat = []\n",
    "                zdr_mean = []\n",
    "                zdr_cc_mean = []\n",
    "                zdr_max = []\n",
    "                zdr_storm_lon = []\n",
    "                zdr_storm_lat = []\n",
    "                zdr_dist = []\n",
    "                zdr_forw = []\n",
    "                zdr_back = []\n",
    "                #print(\"here too\")\n",
    "                for col in zdrc.collections:\n",
    "                    # Loop through all polygons that have the same intensity level\n",
    "                    #print('hi')\n",
    "                    for contour_path in col.get_paths(): \n",
    "                        # Create the polygon for this intensity level\n",
    "                        # The first polygon in the path is the main one, the following ones are \"holes\"\n",
    "                        #print('hi')\n",
    "                        for ncp,cp in enumerate(contour_path.to_polygons()):\n",
    "                            #print('hi')\n",
    "                            cpa = np.asarray(cp[:])\n",
    "                            x = cpa[:,0]\n",
    "                            y = cpa[:,1]\n",
    "                            new_shape = geometry.Polygon([(i[0], i[1]) for i in zip(x,y)])\n",
    "                            if ncp == 0:\n",
    "                                poly = new_shape\n",
    "                                #print('hi')\n",
    "                            else:\n",
    "                                # Remove the holes if there are any\n",
    "                                poly = poly.difference(new_shape)\n",
    "                                #print('hi')\n",
    "\n",
    "                        # do something with polygon\n",
    "                        #print(poly.area) \n",
    "                        #print(poly.centroid.x)\n",
    "                        s_new = transform(proj, poly)\n",
    "                        projected_area = (transform(proj, poly).area * units('m^2')).to('km^2')\n",
    "                        boundary = np.asarray(poly.boundary.xy)\n",
    "                        polypath = Path(boundary.transpose())\n",
    "                        coord_map = np.vstack((rlons[0,:,:].flatten(), rlats[0,:,:].flatten())).T # create an Mx2 array listing all the coordinates in field\n",
    "                        mask = polypath.contains_points(coord_map).reshape(rlons[0,:,:].shape)\n",
    "                        mean = np.mean(ZDRmasked[mask])\n",
    "                        mean_cc = np.mean(CC[mask])\n",
    "                        if projected_area > 1 * units('km^2') and mean > zdrlev[0] and mean_cc > .88:\n",
    "                            g = Geod(ellps='sphere')\n",
    "                            dist = np.zeros((np.asarray(max_lons_c).shape[0]))\n",
    "                            forw = np.zeros((np.asarray(max_lons_c).shape[0]))\n",
    "                            back = np.zeros((np.asarray(max_lons_c).shape[0]))\n",
    "                            for i in range(dist.shape[0]):\n",
    "                                        distance_1 = g.inv(poly.centroid.x, poly.centroid.y,\n",
    "                                                               max_lons_c[i], max_lats_c[i])\n",
    "                                        #print(distance_1[2]/1000)\n",
    "                                        #print(distance_1)\n",
    "                                        back[i] = distance_1[1]\n",
    "                                        if distance_1[1] < 0:\n",
    "                                            back[i] = distance_1[1] + 360\n",
    "                                        forw[i] = np.abs(back[i] - storm_relative_dir)\n",
    "                                        dist[i] = distance_1[2]/1000.\n",
    "                            #print(dist.shape)\n",
    "                            if (forw[np.where(dist == np.min(dist))[0][0]] < 90 and np.min(dist) < 20.0) or (forw[np.where(dist == np.min(dist))[0][0]] < 140 and np.min(dist) < 6.0):\n",
    "                                zdr_storm_lon.append((max_lons_c[np.where(dist == np.min(dist))[0][0]]))\n",
    "                                zdr_storm_lat.append((max_lats_c[np.where(dist == np.min(dist))[0][0]]))\n",
    "                                zdr_dist.append(np.min(dist))\n",
    "                                zdr_forw.append(forw[np.where(dist == np.min(dist))[0][0]])\n",
    "                                zdr_back.append(back[np.where(dist == np.min(dist))[0][0]])\n",
    "                                zdr_areas.append((projected_area))\n",
    "                                zdr_centroid_lon.append((poly.centroid.x))\n",
    "                                zdr_centroid_lat.append((poly.centroid.y))\n",
    "                                zdr_mean.append((mean))\n",
    "                                zdr_cc_mean.append((mean_cc))\n",
    "                                zdr_max.append((np.max(ZDRmasked[mask])))\n",
    "                                patch = PathPatch(polypath, facecolor='none', alpha=.8, edgecolor = 'blue', linewidth = 3)\n",
    "                                ax.add_patch(patch)\n",
    "                        #print(s_new)\n",
    "                print('made it through zdr centroids')\n",
    "                \n",
    "                if len(zdr_storm_lon) > 0:\n",
    "                    kdp_areas = []\n",
    "                    kdp_centroid_lon = []\n",
    "                    kdp_centroid_lat = []\n",
    "                    kdp_max = []\n",
    "                    kdp_storm_lon = []\n",
    "                    kdp_storm_lat = []\n",
    "                    for col in kdpc.collections:\n",
    "                        # Loop through all polygons that have the same intensity level\n",
    "                        for contour_path in col.get_paths(): \n",
    "                            # Create the polygon for this intensity level\n",
    "                            # The first polygon in the path is the main one, the following ones are \"holes\"\n",
    "                            for ncp,cp in enumerate(contour_path.to_polygons()):\n",
    "                                print(1)\n",
    "                                cpa = np.asarray(cp[:])\n",
    "                                x = cpa[:,0]\n",
    "                                y = cpa[:,1]\n",
    "                                new_shape = geometry.Polygon([(i[0], i[1]) for i in zip(x,y)])\n",
    "                                if ncp == 0:\n",
    "                                    poly = new_shape\n",
    "                                else:\n",
    "                                    # Remove the holes if there are any\n",
    "                                    poly = poly.difference(new_shape)\n",
    "\n",
    "                            # do something with polygon\n",
    "                            #print(poly.area) \n",
    "                            print(poly.centroid.x)\n",
    "                            s_new = transform(proj, poly)\n",
    "                            projected_area = (transform(proj, poly).area * units('m^2')).to('km^2')\n",
    "                            boundary = np.asarray(poly.boundary.xy)\n",
    "                            polypath = Path(boundary.transpose())\n",
    "                            coord_map = np.vstack((rlons[0,:,:].flatten(), rlats[0,:,:].flatten())).T # create an Mx2 array listing all the coordinates in field\n",
    "                            mask_kdp = polypath.contains_points(coord_map).reshape(rlons[0,:,:].shape)\n",
    "                            #mean = np.mean(ZDRmasked[mask])\n",
    "                            #mask = polypath.contains_points(coord_map).reshape(rlons[0,:,:].shape)\n",
    "                            #mean = np.mean(REFmasked[mask])\n",
    "                            if projected_area > 2 * units('km^2'):\n",
    "                                g = Geod(ellps='sphere')\n",
    "                                dist_kdp = np.zeros((np.asarray(max_lons_c).shape[0]))\n",
    "                                for i in range(dist_kdp.shape[0]):\n",
    "                                            distance_kdp = g.inv(poly.centroid.x, poly.centroid.y,\n",
    "                                                                   max_lons_c[i], max_lats_c[i])\n",
    "                                            #print(distance_1[2]/1000)\n",
    "                                            #print(\"KDP dist:\", distance_kdp)\n",
    "                                            dist_kdp[i] = distance_kdp[2]/1000.\n",
    "                                print(dist_kdp)\n",
    "                                if np.min(np.asarray(dist_kdp)) < 15.0:\n",
    "                                    #print('Got to KDP stuff')\n",
    "                                    kdp_areas.append((projected_area))\n",
    "                                    kdp_centroid_lon.append((poly.centroid.x))\n",
    "                                    kdp_centroid_lat.append((poly.centroid.y))\n",
    "                                    kdp_storm_lon.append((max_lons_c[np.where(dist_kdp == np.min(dist_kdp))[0][0]]))\n",
    "                                    kdp_storm_lat.append((max_lats_c[np.where(dist_kdp == np.min(dist_kdp))[0][0]]))\n",
    "                                    kdp_max.append((np.max(KDPmasked[mask_kdp])))\n",
    "                                    patch = PathPatch(polypath, facecolor='none', alpha=.5, edgecolor = 'grey', linewidth = 3)\n",
    "                                    ax.add_patch(patch)\n",
    "                \n",
    "                    print('made it through kdp centroids')\n",
    "\n",
    "                    #Consolidating the arc objects associated with each storm:\n",
    "                    zdr_areas_arr = np.zeros((len(zdr_areas)))\n",
    "                    zdr_max_arr = np.zeros((len(zdr_max)))\n",
    "                    zdr_mean_arr = np.zeros((len(zdr_mean)))                    \n",
    "                    for i in range(len(zdr_areas)):\n",
    "                        zdr_areas_arr[i] = zdr_areas[i].magnitude\n",
    "                        zdr_max_arr[i] = zdr_max[i]\n",
    "                        zdr_mean_arr[i] = zdr_mean[i]\n",
    "\n",
    "                    zdr_centroid_lons = np.asarray(zdr_centroid_lon)\n",
    "                    zdr_centroid_lats = np.asarray(zdr_centroid_lat)\n",
    "                    zdr_con_areas = []\n",
    "                    zdr_con_maxes = []\n",
    "                    zdr_con_means = []\n",
    "                    zdr_con_centroid_lon = []\n",
    "                    zdr_con_centroid_lat = []\n",
    "                    zdr_con_max_lon = []\n",
    "                    zdr_con_max_lat = []\n",
    "                    zdr_con_storm_lon = []\n",
    "                    zdr_con_storm_lat = []\n",
    "\n",
    "                    #For KDP as well\n",
    "                    kdp_areas_arr = np.zeros((len(kdp_areas)))\n",
    "                    kdp_max_arr = np.zeros((len(kdp_max)))\n",
    "                    for i in range(len(kdp_areas)):\n",
    "                        kdp_areas_arr[i] = kdp_areas[i].magnitude\n",
    "                        kdp_max_arr[i] = kdp_max[i]\n",
    "                    kdp_centroid_lons = np.asarray(kdp_centroid_lon)\n",
    "                    kdp_centroid_lats = np.asarray(kdp_centroid_lat)\n",
    "                    kdp_con_areas = []\n",
    "                    kdp_con_maxes = []\n",
    "                    kdp_con_centroid_lon = []\n",
    "                    kdp_con_centroid_lat = []\n",
    "                    kdp_con_max_lon = []\n",
    "                    kdp_con_max_lat = []\n",
    "                    kdp_con_storm_lon = []\n",
    "                    kdp_con_storm_lat = []\n",
    "                    for i in enumerate(zdr_storm_lon):\n",
    "                        print(i[0])\n",
    "                        if i[0] != 0:\n",
    "                            if zdr_storm_lon[i[0]-1] == zdr_storm_lon[i[0]]:\n",
    "                                #print(\"Skipping this one\")\n",
    "                                continue\n",
    "                            else:\n",
    "                                print(zdr_storm_lon[i[0]])\n",
    "                                #Find the arc objects associated with this storm:\n",
    "                                zdr_objects_lons = zdr_centroid_lons[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])]\n",
    "                                zdr_objects_lats = zdr_centroid_lats[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])]\n",
    "                                #print(\"zdr lons:\", zdr_objects_lons)\n",
    "                                #Get the sum of their areas\n",
    "                                print(zdr_areas_arr[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])])\n",
    "                                zdr_con_areas.append(np.sum(zdr_areas_arr[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])]))\n",
    "                                zdr_con_maxes.append(np.max(zdr_max_arr[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])]))\n",
    "                                zdr_con_means.append(np.mean(zdr_mean_arr[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])]))\n",
    "                                zdr_con_max_lon.append(rlons_2d[np.where(ZDRmasked==np.max(zdr_max_arr[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])]))])\n",
    "                                zdr_con_max_lat.append(rlats_2d[np.where(ZDRmasked==np.max(zdr_max_arr[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])]))])\n",
    "                                #print(\"Areas sum:\", zdr_con_areas)\n",
    "                                #Find the actual centroids\n",
    "                                weighted_lons = zdr_objects_lons * zdr_areas_arr[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])]\n",
    "                                zdr_con_centroid_lon.append(np.sum(weighted_lons) / np.sum(zdr_areas_arr[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])]))\n",
    "                                weighted_lats = zdr_objects_lats * zdr_areas_arr[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])]\n",
    "                                zdr_con_centroid_lat.append(np.sum(weighted_lats) / np.sum(zdr_areas_arr[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])]))\n",
    "                                zdr_con_storm_lon.append(zdr_storm_lon[i[0]])\n",
    "                                zdr_con_storm_lat.append(zdr_storm_lat[i[0]])\n",
    "                                #print(\"New centroid lon:\", zdr_con_centroid_lon, \"New centroid lat:\", zdr_con_centroid_lat)\n",
    "                                #print(\"lons in loop\", zdr_objects_lons)\n",
    "\n",
    "                                try:\n",
    "                                    #Find the kdp objects associated with this storm:\n",
    "                                    kdp_objects_lons = kdp_centroid_lons[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])]\n",
    "                                    #print(\"kdp lons:\", kdp_objects_lons)\n",
    "                                    kdp_objects_lats = kdp_centroid_lats[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])]\n",
    "                                    #Get the sum of their areas\n",
    "                                    print(kdp_areas_arr[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])])\n",
    "                                    kdp_con_areas.append(np.sum(kdp_areas_arr[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])]))\n",
    "                                    kdp_con_maxes.append(np.max(kdp_max_arr[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])]))\n",
    "                                    kdp_con_max_lon.append(rlons_2d[np.where(KDPmasked==np.max(kdp_max_arr[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])]))])\n",
    "                                    kdp_con_max_lat.append(rlats_2d[np.where(KDPmasked==np.max(kdp_max_arr[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])]))])\n",
    "                                    #Find the actual centroids\n",
    "                                    weighted_lons_kdp = kdp_objects_lons * kdp_areas_arr[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])]\n",
    "                                    kdp_con_centroid_lon.append(np.sum(weighted_lons_kdp) / np.sum(kdp_areas_arr[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])]))\n",
    "                                    weighted_lats_kdp = kdp_objects_lats * kdp_areas_arr[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])]\n",
    "                                    #print(\"Could be it:\",\"weighted lons:\",weighted_lons_kdp, \"object lons\",kdp_objects_lons, \"areas:\",kdp_areas_arr[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])])\n",
    "                                    kdp_con_centroid_lat.append(np.sum(weighted_lats_kdp) / np.sum(kdp_areas_arr[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])]))\n",
    "                                    kdp_con_storm_lon.append(zdr_storm_lon[i[0]])\n",
    "                                    kdp_con_storm_lat.append(zdr_storm_lat[i[0]])\n",
    "                                except:\n",
    "                                    print('storm missing kdp or zdr')\n",
    "                                    kdp_con_areas.append(0)\n",
    "                                    kdp_con_maxes.append(0)\n",
    "                                    kdp_con_max_lon.append(0)\n",
    "                                    kdp_con_max_lat.append(0)\n",
    "                                    kdp_con_centroid_lon.append(0)\n",
    "                                    kdp_con_centroid_lat.append(0)\n",
    "                                    kdp_con_storm_lon.append(0)\n",
    "                                    kdp_con_storm_lat.append(0)\n",
    "\n",
    "\n",
    "\n",
    "                        else:\n",
    "                            #print(zdr_storm_lon[i[0]])\n",
    "                            #Find the arc objects associated with this storm:\n",
    "                            zdr_objects_lons = zdr_centroid_lons[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])]\n",
    "                            zdr_objects_lats = zdr_centroid_lats[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])]\n",
    "                            #print(\"zdr lons:\", zdr_objects_lons)\n",
    "                            #print(\"arc lats:\", zdr_objects_lats)\n",
    "                            #Get the sum of their areas\n",
    "                            #print(zdr_areas_arr[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])])\n",
    "                            zdr_con_areas.append(np.sum(zdr_areas_arr[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])]))\n",
    "                            zdr_con_maxes.append(np.max(zdr_max_arr[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])]))\n",
    "                            zdr_con_means.append(np.mean(zdr_mean_arr[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])]))\n",
    "                            zdr_con_max_lon.append(rlons_2d[np.where(ZDRmasked==np.max(zdr_max_arr[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])]))])\n",
    "                            zdr_con_max_lat.append(rlats_2d[np.where(ZDRmasked==np.max(zdr_max_arr[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])]))])\n",
    "                            #print(\"Areas sum:\",zdr_con_areas)\n",
    "                            #Find the actual centroids\n",
    "                            weighted_lons = zdr_objects_lons * zdr_areas_arr[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])]\n",
    "                            zdr_con_centroid_lon.append(np.sum(weighted_lons) / np.sum(zdr_areas_arr[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])]))\n",
    "                            weighted_lats = zdr_objects_lats * zdr_areas_arr[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])]\n",
    "                            zdr_con_centroid_lat.append(np.sum(weighted_lats) / np.sum(zdr_areas_arr[np.where(zdr_storm_lon == zdr_storm_lon[i[0]])]))\n",
    "                            zdr_con_storm_lon.append(zdr_storm_lon[i[0]])\n",
    "                            zdr_con_storm_lat.append(zdr_storm_lat[i[0]])\n",
    "                            #print(\"New centroid lon:\", zdr_con_centroid_lon, \"New centroid lat:\", zdr_con_centroid_lat)\n",
    "                            #print(\"lons out of loop\", zdr_objects_lons)\n",
    "                            try:\n",
    "                                #Find the kdp objects associated with this storm:\n",
    "                                kdp_objects_lons = kdp_centroid_lons[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])]\n",
    "                                #print(\"kdp lons:\", kdp_objects_lons)\n",
    "                                kdp_objects_lats = kdp_centroid_lats[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])]\n",
    "                                #Get the sum of their areas\n",
    "                                #print(kdp_areas_arr[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])])\n",
    "                                kdp_con_areas.append(np.sum(kdp_areas_arr[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])]))\n",
    "                                kdp_con_maxes.append(np.max(kdp_max_arr[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])]))\n",
    "                                kdp_con_max_lon.append(rlons_2d[np.where(KDPmasked==np.max(kdp_max_arr[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])]))])\n",
    "                                kdp_con_max_lat.append(rlats_2d[np.where(KDPmasked==np.max(kdp_max_arr[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])]))])\n",
    "                                #Find the actual centroids\n",
    "                                weighted_lons_kdp = kdp_objects_lons * kdp_areas_arr[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])]\n",
    "                                kdp_con_centroid_lon.append(np.sum(weighted_lons_kdp) / np.sum(kdp_areas_arr[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])]))\n",
    "                                weighted_lats_kdp = kdp_objects_lats * kdp_areas_arr[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])]\n",
    "                                #print(\"Could be it:\",\"weighted lons:\",weighted_lons_kdp, \"object lons\",kdp_objects_lons, \"areas:\",kdp_areas_arr[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])])\n",
    "                                kdp_con_centroid_lat.append(np.sum(weighted_lats_kdp) / np.sum(kdp_areas_arr[np.where(kdp_storm_lon == zdr_storm_lon[i[0]])]))\n",
    "                                kdp_con_storm_lon.append(zdr_storm_lon[i[0]])\n",
    "                                kdp_con_storm_lat.append(zdr_storm_lat[i[0]])\n",
    "                            except:\n",
    "                                print('storm missing kdp or zdr')\n",
    "                                kdp_con_areas.append(0)\n",
    "                                kdp_con_maxes.append(0)\n",
    "                                kdp_con_max_lon.append(0)\n",
    "                                kdp_con_max_lat.append(0)\n",
    "                                kdp_con_centroid_lon.append(0)\n",
    "                                kdp_con_centroid_lat.append(0)\n",
    "                                kdp_con_storm_lon.append(0)\n",
    "                                kdp_con_storm_lat.append(0)\n",
    "                                    \n",
    "                    #Calculate KDP-ZDR separation\n",
    "                    print('calculating separation')\n",
    "                    kdp_con_centroid_lons1 = np.asarray(kdp_con_centroid_lon)\n",
    "                    kdp_con_centroid_lats1 = np.asarray(kdp_con_centroid_lat)\n",
    "                    zdr_con_centroid_lons1 = np.asarray(zdr_con_centroid_lon)\n",
    "                    zdr_con_centroid_lats1 = np.asarray(zdr_con_centroid_lat)\n",
    "                    #Eliminate consolidated arcs smaller than a specified area\n",
    "                    area = 2\n",
    "                    zdr_con_areas_arr = np.asarray(zdr_con_areas)\n",
    "                    zdr_con_centroid_lats = zdr_con_centroid_lats1[zdr_con_areas_arr > area]\n",
    "                    zdr_con_centroid_lons = zdr_con_centroid_lons1[zdr_con_areas_arr > area]\n",
    "                    kdp_con_centroid_lats = kdp_con_centroid_lats1[zdr_con_areas_arr > area]\n",
    "                    kdp_con_centroid_lons = kdp_con_centroid_lons1[zdr_con_areas_arr > area]\n",
    "                    zdr_con_max_lons1 = np.asarray(zdr_con_max_lon)[zdr_con_areas_arr > area]\n",
    "                    zdr_con_max_lats1 = np.asarray(zdr_con_max_lat)[zdr_con_areas_arr > area]\n",
    "                    kdp_con_max_lons1 = np.asarray(kdp_con_max_lon)[zdr_con_areas_arr > area]\n",
    "                    kdp_con_max_lats1 = np.asarray(kdp_con_max_lat)[zdr_con_areas_arr > area]\n",
    "                    print('Boolean problem here')\n",
    "                    zdr_con_areas1 = zdr_con_areas_arr[zdr_con_areas_arr > area]\n",
    "\n",
    "                    kdp_inds = np.where(kdp_con_centroid_lats > 0)\n",
    "                    distance_kdp_zdr = g.inv(kdp_con_centroid_lons[kdp_inds], kdp_con_centroid_lats[kdp_inds], zdr_con_centroid_lons[kdp_inds], zdr_con_centroid_lats[kdp_inds])\n",
    "                    dist_kdp_zdr = distance_kdp_zdr[2] / 1000.\n",
    "                    #Now make an array for the distances which will have the same shape as the lats to prevent errors\n",
    "                    shaped_dist = np.zeros((np.shape(zdr_con_areas)))\n",
    "                    shaped_dist[kdp_inds] = dist_kdp_zdr\n",
    "                    print('maybe its here')\n",
    "                    #Do the same for the distances between the maxes\n",
    "                    distance_kdp_zdr_max = g.inv(kdp_con_max_lons1[kdp_inds], kdp_con_max_lats1[kdp_inds], zdr_con_max_lons1[kdp_inds], zdr_con_max_lats1[kdp_inds])\n",
    "                    dist_kdp_zdr_max = distance_kdp_zdr_max[2] / 1000.\n",
    "                    #Now make an array for the distances which will have the same shape as the lats to prevent errors\n",
    "                    shaped_dist_max = np.zeros((np.shape(zdr_con_areas)))\n",
    "                    shaped_dist_max[kdp_inds] = dist_kdp_zdr_max\n",
    "                    print('or not')\n",
    "                    \n",
    "                else:\n",
    "                    print('No ZDR arcs')\n",
    "                    kdp_areas = []\n",
    "                    kdp_centroid_lon = []\n",
    "                    kdp_centroid_lat = []\n",
    "                    kdp_storm_lon = []\n",
    "                    kdp_storm_lat = []\n",
    "                    zdr_con_centroid_lats = []\n",
    "                    zdr_con_centroid_lons = []\n",
    "                    kdp_con_centroid_lats = []\n",
    "                    kdp_con_centroid_lons = []\n",
    "                    kdp_con_area = []\n",
    "                    zdr_con_areas1 = []\n",
    "                    \n",
    "                ###Now let's consolidate everything to fit the Pandas dataframe!\n",
    "                p_zdr_areas = []\n",
    "                p_zdr_maxes = []\n",
    "                p_zdr_means = []\n",
    "                p_separations = []\n",
    "                if len(zdr_storm_lon) > 0:\n",
    "                    for storm in enumerate(max_lons_c):\n",
    "                        print(storm)\n",
    "                        print(np.flatnonzero(np.isclose(max_lons_c[storm[0]], zdr_con_storm_lon, rtol=1e-05)))\n",
    "                        matching_ind = np.flatnonzero(np.isclose(max_lons_c[storm[0]], zdr_con_storm_lon, rtol=1e-05))\n",
    "                        if matching_ind.shape[0] > 0:\n",
    "                            p_zdr_areas.append((zdr_con_areas[matching_ind[0]]))\n",
    "                            p_zdr_maxes.append((zdr_con_maxes[matching_ind[0]]))\n",
    "                            p_zdr_means.append((zdr_con_means[matching_ind[0]]))\n",
    "                            p_separations.append((shaped_dist[matching_ind[0]]))\n",
    "                        else:\n",
    "                            p_zdr_areas.append((0))\n",
    "                            p_zdr_maxes.append((0))\n",
    "                            p_zdr_means.append((0))\n",
    "                            p_separations.append((0))\n",
    "                else:\n",
    "                    for storm in enumerate(max_lons_c):\n",
    "                        p_zdr_areas.append((0))\n",
    "                        p_zdr_maxes.append((0))\n",
    "                        p_zdr_means.append((0))\n",
    "                        p_separations.append((0))\n",
    "                    \n",
    "                #Now start plotting stuff!\n",
    "                print('made it through giant if statement')\n",
    "                if np.asarray(zdr_centroid_lon).shape[0] > 0:\n",
    "                    ax.scatter(zdr_centroid_lon, zdr_centroid_lat, marker = '*', s = 100, color = 'black', zorder = 10, transform=ccrs.PlateCarree())\n",
    "                    #ax.scatter(zdr_con_max_lon, zdr_con_max_lat, marker = '*', s = 100, color = 'purple', zorder = 10, transform=ccrs.PlateCarree())\n",
    "                if np.asarray(kdp_centroid_lon).shape[0] > 0:\n",
    "                    ax.scatter(kdp_centroid_lon, kdp_centroid_lat, marker = '^', s = 100, color = 'black', zorder = 10, transform=ccrs.PlateCarree())\n",
    "                    #ax.scatter(kdp_con_max_lon, kdp_con_max_lat, marker = '^', s = 100, color = 'purple', zorder = 10, transform=ccrs.PlateCarree())\n",
    "                print(\"plotted centroids\")\n",
    "                #Uncomment to print all object areas\n",
    "                #for i in enumerate(zdr_areas):\n",
    "                #    plt.text(zdr_centroid_lon[i[0]]+.016, zdr_centroid_lat[i[0]]+.016, \"%.2f km^2\" %(zdr_areas[i[0]].magnitude), size = 23)\n",
    "                    #plt.text(zdr_centroid_lon[i[0]]+.016, zdr_centroid_lat[i[0]]+.016, \"%.2f km^2 / %.2f km / %.2f dB\" %(zdr_areas[i[0]].magnitude, zdr_dist[i[0]], zdr_forw[i[0]]), size = 23)\n",
    "                    #plt.annotate(zdr_areas[i[0]], (zdr_centroid_lon[i[0]],zdr_centroid_lat[i[0]]))\n",
    "                #ax.contourf(rlons[0,:,:],rlats[0,:,:],KDPmasked,KDPlevels1,linewide = .01, colors ='b', alpha = .5)\n",
    "                #plt.tight_layout()\n",
    "                #plt.savefig('ZDRarcannotated.png')\n",
    "                storm_times = []\n",
    "                for l in range(len(max_lons_c)):\n",
    "                    storm_times.append((time_start))\n",
    "                #Now record all data in a Pandas dataframe, using similar code as Tint (kind of borrowed from it)\n",
    "                print('making dataframe')\n",
    "                new_cells = pd.DataFrame({\n",
    "                    'scan': scan_index,\n",
    "                    'storm_id' : storm_ids,\n",
    "                    'storm_id1' : storm_ids,\n",
    "                    'storm_lon' : max_lons_c,\n",
    "                    'storm_lat' : max_lats_c,\n",
    "                    'zdr_area' : p_zdr_areas,\n",
    "                    'zdr_max' : p_zdr_maxes,\n",
    "                    'zdr_mean' : p_zdr_means,\n",
    "                    'kdp_zdr_sep' : p_separations,\n",
    "                    'times' : storm_times\n",
    "                })\n",
    "                print('setting index')\n",
    "                new_cells.set_index(['scan', 'storm_id'], inplace=True)\n",
    "                if scan_index == 0:\n",
    "                    print('first dataframe')\n",
    "                    tracks_dataframe = new_cells\n",
    "                else:\n",
    "                    tracks_dataframe = tracks_dataframe.append(new_cells)\n",
    "                n = n+1\n",
    "                scan_index = scan_index + 1\n",
    "                #max_lons_p = max_lons_c\n",
    "                #max_lats_p = max_lats_c\n",
    "                #storm_ids_p = storm_ids\n",
    "                #Plot the consolidated stuff!\n",
    "                print('made it to plotting')\n",
    "                if len(zdr_con_areas1) > 0:\n",
    "                    #ax.scatter(zdr_con_centroid_lon, zdr_con_centroid_lat, marker = '*', s = 500, color = 'orange', zorder = 10, transform=ccrs.PlateCarree())\n",
    "                    try:\n",
    "                        for i in enumerate(zdr_con_centroid_lats):\n",
    "                            print(\"consolidated ZDR:\")\n",
    "                            ax.scatter(zdr_con_centroid_lons, zdr_con_centroid_lats, marker = '*', s = 500, color = 'orange', zorder = 10, transform=ccrs.PlateCarree())\n",
    "                            try:\n",
    "                                plt.text(zdr_con_centroid_lons[i[0]]+.025, zdr_con_centroid_lats[i[0]]+.016, \"%.2f km^2 / %.2f dB\" %(zdr_con_areas1[i[0]], zdr_con_maxes[i[0]]), size = 23)\n",
    "                            except:\n",
    "                                print(\"oops zdr\")\n",
    "                        #plt.text(kdp_con_centroid_lon[i[0]]-.20, kdp_con_centroid_lat[i[0]]+.016, \"%.2f km\" %(dist_kdp_zdr[i[0]]), size = 23, color = 'red')                \n",
    "                    except:\n",
    "                        print('failed')\n",
    "                        try:\n",
    "                            plt.text(float(zdr_con_centroid_lons)+.016, float(zdr_con_centroid_lats)+.016, \"%.2f km^2 / %.2f dB\" %(zdr_con_areas1[i[0]], zdr_con_maxes[i[0]]), size = 23)\n",
    "                        except:\n",
    "                            print('no zdr centroids')\n",
    "                        #plt.text(float(kdp_con_centroid_lon)-.20, float(kdp_con_centroid_lat)+.016, \"%.2f km\" %(float(dist_kdp_zdr[0])), size = 23, color = 'red')\n",
    "                    if len(kdp_con_areas) > 0:\n",
    "                        #ax.scatter(zdr_con_centroid_lon, zdr_con_centroid_lat, marker = '*', s = 500, color = 'orange', zorder = 10, transform=ccrs.PlateCarree())\n",
    "                        try:\n",
    "                            for i in kdp_inds[0]:\n",
    "                                #plt.text(zdr_con_centroid_lon[i[0]]+.025, zdr_con_centroid_lat[i[0]]+.016, \"%.2f km^2\" %(zdr_con_areas[i[0]].magnitude), size = 23)\n",
    "                                try:\n",
    "                                    plt.text(kdp_con_centroid_lons[i]-.20, kdp_con_centroid_lats[i]+.016, \"%.2f km\" %(shaped_dist[i]), size = 23, color = 'red')                \n",
    "                                except:\n",
    "                                    print('oops kdp')\n",
    "                        except:\n",
    "                            print('failed')\n",
    "                            #plt.text(float(zdr_con_centroid_lon)+.016, float(zdr_con_centroid_lat)+.016, \"%.2f km^2\" %(float(zdr_con_areas[0])), size = 23)\n",
    "                            try:\n",
    "                                plt.text(float(kdp_con_centroid_lons)-.20, float(kdp_con_centroid_lats)+.016, \"%.2f km\" %(float(shaped_dist[0])), size = 23, color = 'red')\n",
    "                            except:\n",
    "                                print('no kdp centroids')\n",
    "                    else:\n",
    "                        print('No kdp')\n",
    "                else:\n",
    "                    print('No zdr arcs')\n",
    "                print(\"means there's a kdp problem\")\n",
    "                hour = time_start.hour\n",
    "                if hour < 10:\n",
    "                    hour = '0'+str(hour)\n",
    "                minute = time_start.minute\n",
    "                if minute < 10:\n",
    "                    minute = '0'+str(minute)\n",
    "                day = time_start.day\n",
    "                if day < 10:\n",
    "                    day = '0'+str(day)\n",
    "                title_plot = plt.title(station+' Radar Reflectivity, ZDR, and KDP '+str(time_start.year)+'-'+str(time_start.month)+'-'+str(time_start.day)+\n",
    "                                           ' '+str(hour)+':'+str(minute)+' UTC', size = 25)\n",
    "                #if np.asarray(zdr_storm_lon).shape[0] > 0:\n",
    "                #    ax.scatter(zdr_storm_lon,zdr_storm_lat, marker = \"o\", color = 'purple', s = 500)\n",
    "                #if np.asarray(kdp_storm_lon).shape[0] > 0:\n",
    "                #    ax.scatter(kdp_storm_lon,kdp_storm_lat, marker = \"o\", color = 'purple', s = 500)\n",
    "                try:\n",
    "                    ax.scatter(max_lons_c,max_lats_c, marker = \"o\", color = 'k', s = 500, alpha = .6)\n",
    "                except:\n",
    "                    \"No storm centroids found\"\n",
    "                try:\n",
    "                    plt.plot([zdr_con_centroid_lons[kdp_inds], kdp_con_centroid_lons[kdp_inds]], [zdr_con_centroid_lats[kdp_inds],kdp_con_centroid_lats[kdp_inds]], color = 'k', linewidth = 5, transform=ccrs.PlateCarree())\n",
    "                except:\n",
    "                    print('KDP-ZDR separation didt work')\n",
    "                ref_centroid_lon = max_lons_c\n",
    "                ref_centroid_lat = max_lats_c\n",
    "                for i in enumerate(ref_centroid_lon): \n",
    "                    plt.text(ref_centroid_lon[i[0]]+.016, ref_centroid_lat[i[0]]+.016, \"storm_id: %.1f\" %(storm_ids[i[0]]), size = 25)\n",
    "                #Comment out this line if not plotting tornado tracks\n",
    "                #plt.plot([start_torlons, end_torlons], [start_torlats, end_torlats], color = 'purple', linewidth = 5, transform=ccrs.PlateCarree())\n",
    "                #Add legend stuff\n",
    "                zdr_outline = mlines.Line2D([], [], color='blue', linewidth = 5, linestyle = 'solid', label='ZDR Arc Outline(Area/Max)')\n",
    "                kdp_outline = mlines.Line2D([], [], color='green', linewidth = 5,linestyle = 'solid', label='\"KDP Foot\" Outline')\n",
    "                separation_vector = mlines.Line2D([], [], color='black', linewidth = 5,linestyle = 'solid', label='KDP/ZDR Centroid Separation Vector (Red Text=Distance)')\n",
    "                tor_track = mlines.Line2D([], [], color='purple', linewidth = 5,linestyle = 'solid', label='Tornado Tracks')\n",
    "                elevation = mlines.Line2D([], [], color='grey', linewidth = 5,linestyle = 'solid', label='Height AGL (m)')\n",
    "\n",
    "                plt.legend(handles=[zdr_outline, kdp_outline, separation_vector, tor_track, elevation], loc = 3, fontsize = 25)\n",
    "                alt_levs = [1000, 2000]\n",
    "                cele = ax.contour(ungrid_lons,ungrid_lats,gate_altitude,alt_levs, linewidths = 7, alpha = .6, colors = 'grey')\n",
    "                plt.clabel(cele, fontsize=18, inline=1, inline_spacing=10, fmt='%i', rightside_up=True, use_clabeltext=True)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig('Example_ZDRArc_comp'+station+str(time_start.year)+str(time_start.month)+str(day)+str(hour)+str(minute)+'.png')\n",
    "                print('figure saved')\n",
    "                plt.close()\n",
    "\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save off the dataframe as a pickle file\n",
    "tracks_dataframe.to_pickle('ExampleCase_7_11_17KMVX.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
